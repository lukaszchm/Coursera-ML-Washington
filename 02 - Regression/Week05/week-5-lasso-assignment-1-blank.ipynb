{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.8.3) is available! Your current version is v1.8.1.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This non-commercial license of GraphLab Create is assigned to zerth.sp@gmail.com and will expire on December 13, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-1284 - Server binary: c:\\Python27\\dato-env\\Lib\\site-packages\\graphlab\\unity_server.exe - Server log: C:\\Users\\luchmiel\\AppData\\Local\\Temp\\graphlab_server_1456749404.log.0\n",
      "[INFO] GraphLab Server Version: 1.8.1\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 21613\n",
      "PROGRESS: Number of features          : 17\n",
      "PROGRESS: Number of unpacked features : 17\n",
      "PROGRESS: Number of coefficients    : 18\n",
      "PROGRESS: Starting Accelerated Gradient (FISTA)\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: Tuning step size. First iteration could take longer than subsequent iterations.\n",
      "PROGRESS: | 1         | 2        | 0.000002  | 1.157742     | 6962915.603493     | 426631.749026 |\n",
      "PROGRESS: | 2         | 3        | 0.000002  | 1.174130     | 6843144.200219     | 392488.929838 |\n",
      "PROGRESS: | 3         | 4        | 0.000002  | 1.177472     | 6831900.032123     | 385340.166783 |\n",
      "PROGRESS: | 4         | 5        | 0.000002  | 1.193098     | 6847166.848958     | 384842.383767 |\n",
      "PROGRESS: | 5         | 6        | 0.000002  | 1.212300     | 6869667.895833     | 385998.458623 |\n",
      "PROGRESS: | 6         | 7        | 0.000002  | 1.225309     | 6847177.773672     | 380824.455891 |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: TERMINATED: Iteration limit reached.\n",
      "PROGRESS: This model may not be optimal. To improve it, consider increasing `max_iterations`.\n"
     ]
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n",
      "|       name       |     value     |\n",
      "+------------------+---------------+\n",
      "|   (intercept)    |  274873.05595 |\n",
      "|    bathrooms     | 8468.53108691 |\n",
      "|   sqft_living    | 24.4207209824 |\n",
      "| sqft_living_sqrt | 350.060553386 |\n",
      "|      grade       | 842.068034898 |\n",
      "|    sqft_above    | 20.0247224171 |\n",
      "+------------------+---------------+\n",
      "[6 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_all.coefficients[model_all.coefficients['value'] != 0][['name', 'value']].print_rows(num_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def search_l1_penalty(start, stop, num_models, penalties=None):\n",
    "    if(penalties != None):\n",
    "        _penalties = penalties\n",
    "    else:\n",
    "        _penalties = np.logspace(start, stop, num_models)\n",
    "    rss_list = []\n",
    "    models = []\n",
    "    nnz = []\n",
    "    for penalty in _penalties:\n",
    "        model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                                  validation_set=None, max_iterations=10,\n",
    "                                                  l2_penalty=0., l1_penalty=penalty, \n",
    "                                                  verbose=False)\n",
    "\n",
    "        errors = (model.predict(validation) - validation['price'])\n",
    "        \n",
    "        rss = (errors*errors).sum()\n",
    "        rss_list.append(rss)\n",
    "        models.append(model)\n",
    "        nnz.append(model.coefficients['value'].nnz())\n",
    "\n",
    "    summary_sframe = graphlab.SFrame({\n",
    "            'Penalty': _penalties, \n",
    "            'RSS': rss_list, \n",
    "            'Index': range(len(_penalties)),\n",
    "            'NonZeros': nnz})\n",
    "    \n",
    "    return summary_sframe, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------+-------------------+\n",
      "| Index | NonZeros |    Penalty    |        RSS        |\n",
      "+-------+----------+---------------+-------------------+\n",
      "|   0   |    18    |      10.0     | 6.25766285142e+14 |\n",
      "|   1   |    18    | 31.6227766017 | 6.25766285362e+14 |\n",
      "|   2   |    18    |     100.0     | 6.25766286058e+14 |\n",
      "|   3   |    18    | 316.227766017 | 6.25766288257e+14 |\n",
      "|   4   |    18    |     1000.0    | 6.25766295212e+14 |\n",
      "|   5   |    18    | 3162.27766017 | 6.25766317206e+14 |\n",
      "|   6   |    18    |    10000.0    | 6.25766386761e+14 |\n",
      "|   7   |    18    | 31622.7766017 | 6.25766606749e+14 |\n",
      "|   8   |    18    |    100000.0   | 6.25767302792e+14 |\n",
      "|   9   |    18    | 316227.766017 | 6.25769507644e+14 |\n",
      "|   10  |    18    |   1000000.0   | 6.25776517727e+14 |\n",
      "|   11  |    18    | 3162277.66017 | 6.25799062845e+14 |\n",
      "|   12  |    18    |   10000000.0  | 6.25883719085e+14 |\n",
      "+-------+----------+---------------+-------------------+\n",
      "[13 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary, models = search_l1_penalty(1, 7, 13)\n",
    "summary.sort('RSS', ascending=True).print_rows(num_rows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFCCAYAAACwxz9YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJahAGOEmSJElqEP8f9uyhIy3xRBAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1240b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.xscale('log')\n",
    "plt.plot(summary['Penalty'], summary['RSS'], '-or')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.569836E+14\n"
     ]
    }
   ],
   "source": [
    "best_model = models[int(summary.sort('RSS')[0]['Index'])]\n",
    "test_errors = (best_model.predict(testing) - testing['price']).to_numpy()\n",
    "test_rss = np.dot(test_errors, test_errors.transpose())\n",
    "print(\"%E\") % test_rss\n",
    "#best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+--------+\n",
      "|       name       | index |      value       | stderr |\n",
      "+------------------+-------+------------------+--------+\n",
      "|   (intercept)    |  None |  18993.4272128   |  None  |\n",
      "|     bedrooms     |  None |  7936.96767903   |  None  |\n",
      "| bedrooms_square  |  None |  936.993368193   |  None  |\n",
      "|    bathrooms     |  None |  25409.5889341   |  None  |\n",
      "|   sqft_living    |  None |  39.1151363797   |  None  |\n",
      "| sqft_living_sqrt |  None |  1124.65021281   |  None  |\n",
      "|     sqft_lot     |  None | 0.00348361822299 |  None  |\n",
      "|  sqft_lot_sqrt   |  None |  148.258391011   |  None  |\n",
      "|      floors      |  None |   21204.335467   |  None  |\n",
      "|  floors_square   |  None |  12915.5243361   |  None  |\n",
      "|    waterfront    |  None |  601905.594545   |  None  |\n",
      "|       view       |  None |  93312.8573119   |  None  |\n",
      "|    condition     |  None |  6609.03571245   |  None  |\n",
      "|      grade       |  None |  6206.93999188   |  None  |\n",
      "|    sqft_above    |  None |  43.2870534193   |  None  |\n",
      "|  sqft_basement   |  None |  122.367827534   |  None  |\n",
      "|     yr_built     |  None |  9.43363539372   |  None  |\n",
      "|   yr_renovated   |  None |  56.0720034488   |  None  |\n",
      "+------------------+-------+------------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.coefficients[best_model.coefficients['value'] != 0].print_rows(num_rows=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_8_10_20, models = search_l1_penalty(8, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2976351441.631313, 3792690190.7322536)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_8_10_20 = summary_8_10_20.sort('NonZeros')\n",
    "l1_penalty_min = summary_8_10_20[summary_8_10_20['NonZeros']>=max_nonzeros][0]['Penalty']\n",
    "#l1_penalty_min = log(l1_penalty_min, 10)\n",
    "l1_penalty_max = summary_8_10_20[summary_8_10_20['NonZeros']<=max_nonzeros].sort('NonZeros', ascending=False)[0]['Penalty']\n",
    "#l1_penalty_max = log(l1_penalty_max, 10)\n",
    "l1_penalty_min, l1_penalty_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------+-------------------+\n",
      "| Index | NonZeros |    Penalty    |        RSS        |\n",
      "+-------+----------+---------------+-------------------+\n",
      "|   0   |    10    | 2976351441.63 | 9.66925692362e+14 |\n",
      "|   1   |    10    | 3019316638.95 | 9.74019450085e+14 |\n",
      "|   2   |    10    | 3062281836.27 | 9.81188367942e+14 |\n",
      "|   3   |    10    | 3105247033.59 | 9.89328342459e+14 |\n",
      "|   4   |    10    | 3148212230.92 | 9.98783211266e+14 |\n",
      "|   5   |    10    | 3191177428.24 | 1.00847716702e+15 |\n",
      "|   6   |    10    | 3234142625.56 | 1.01829878055e+15 |\n",
      "|   7   |    10    | 3277107822.88 | 1.02824799221e+15 |\n",
      "|   8   |    8     |  3320073020.2 | 1.03461690923e+15 |\n",
      "|   9   |    8     | 3363038217.52 | 1.03855473594e+15 |\n",
      "|   10  |    8     | 3406003414.84 | 1.04323723787e+15 |\n",
      "|   11  |    7     | 3448968612.16 | 1.04693748875e+15 |\n",
      "|   12  |    7     | 3491933809.48 | 1.05114762561e+15 |\n",
      "|   13  |    7     | 3534899006.81 | 1.05599273534e+15 |\n",
      "|   14  |    7     | 3577864204.13 | 1.06079953176e+15 |\n",
      "|   15  |    6     | 3620829401.45 |  1.0657076895e+15 |\n",
      "|   16  |    6     | 3663794598.77 | 1.06946433543e+15 |\n",
      "|   17  |    6     | 3706759796.09 | 1.07350454959e+15 |\n",
      "|   18  |    6     | 3749724993.41 | 1.07763277558e+15 |\n",
      "|   19  |    6     | 3792690190.73 | 1.08186759232e+15 |\n",
      "+-------+----------+---------------+-------------------+\n",
      "[20 rows x 4 columns]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:4: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "narrow_model, models = search_l1_penalty(0,0,0, l1_penalty_values)\n",
    "narrow_model.print_rows(num_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">value</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(intercept)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">222253.192544</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bedrooms</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">661.722717782</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bathrooms</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15873.9572593</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sqft_living</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">32.4102214513</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sqft_living_sqrt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">690.114773313</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">grade</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2899.42026975</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sqft_above</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">30.0115753022</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[? rows x 4 columns]<br/>Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.<br/>You can use len(sf) to force materialization.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tvalue\tfloat\n",
       "\tstderr\tfloat\n",
       "\n",
       "Rows: Unknown\n",
       "\n",
       "Data:\n",
       "+------------------+-------+---------------+--------+\n",
       "|       name       | index |     value     | stderr |\n",
       "+------------------+-------+---------------+--------+\n",
       "|   (intercept)    |  None | 222253.192544 |  None  |\n",
       "|     bedrooms     |  None | 661.722717782 |  None  |\n",
       "|    bathrooms     |  None | 15873.9572593 |  None  |\n",
       "|   sqft_living    |  None | 32.4102214513 |  None  |\n",
       "| sqft_living_sqrt |  None | 690.114773313 |  None  |\n",
       "|      grade       |  None | 2899.42026975 |  None  |\n",
       "|    sqft_above    |  None | 30.0115753022 |  None  |\n",
       "+------------------+-------+---------------+--------+\n",
       "[? rows x 4 columns]\n",
       "Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.\n",
       "You can use len(sf) to force materialization."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#narrow_model.sort('RSS').print_rows(num_rows=20)\n",
    "best_model = narrow_model[narrow_model['NonZeros']==max_nonzeros].sort('RSS')[0]\n",
    "best_model\n",
    "coeff = models[best_model['Index']].coefficients\n",
    "coeff[coeff['value'] != 0]\n",
    "#coeff = models[narrow_model.sort('RSS')[0]['Index']].coefficients\n",
    "#coeff[coeff['value'] != 0]\n",
    "#model = models[0]\n",
    "#model.coefficients[model.coefficients['value']!=0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
